---
title: Reddit x 100
subtitle: Exploration of community size and other variables
author: Molly Lewis 
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    number_sections: false
    theme: cerulean
    toc_float: true
    code_folding: hide
---
  
  
```{r setup, include = F}
# load packages
library(tidyverse) 
library(knitr)
library(here)
library(anytime)
library(broom)
library(data.table)
library(viridis)


opts_chunk$set(echo = T, message = F, warning = F, 
               error = F, tidy = F,  cache = F, fig.height = 5, fig.width = 5)
source(here("exploratory_analyses/01_reddit_pilot/scripts/make_corr_plot.R"))


get_power_law_exponent <- function(df, predictor, outcome){
  all_parameters <- lm(unlist(log(df[,outcome])) ~ unlist(log(df[,predictor]))) %>%
    tidy() %>%
    mutate(term = c("intercept", predictor))
  
  power_law_exp <- all_parameters[2, "estimate"] %>% 
    unlist(use.names = F) %>%
    round(2)
  
  list(power_law_exp, all_parameters)
}
``` 


```{r}
AUTHOR_COUNTS <-  here("exploratory_analyses/04_systematic_sample_tidy/data/subreddit_meta.csv")
author_count_measures <- read_csv(AUTHOR_COUNTS, col_names = c("subreddit","author_n","word_H","word_mean_n","word_sd","word_total","score_mean",                                                    "score_sd","score_H","comments_n_all", "posts_n_all","comments_posts_ratio")) %>%
  filter(author_n > 100) %>%
  arrange(-author_n) %>%
  mutate(author_rank = 1:n()) %>%
    filter(!(subreddit == "newsokur"))

author_counts <- author_count_measures %>%
  select(subreddit, author_n, author_rank)
```

Summary of findings:

* There's a robust Zipf's law relationship between number of words and community size - I don't think this has ever been shown before!
* Larger communities produce more  comments relative to posts (power law).
* Larger communities have members with longer lifespans
* Larger communities have shorter lags between comments on a thread (power law).
* Larger communities have less churn.
* Larger communities have more inequality across authors in terms of posting - relatively fewer people do more of the posting. 
* Larger communities  have lower (normalized) scores. This is a Zipf-like distribution.
* Larger communities have lower comment entropy (though weak).
* Larger communities have authors that are less coherent with respect to themselves, i.e. change more. 

```{r}
#Implications for language change:
#* Larger communnities: more homogenous input because of inequality across speakers
# More consensus -> faster word gain.
```


## Language counts{.tabset}

More people, more words.
(there's no relationship between mean/sd post length and author n.)

###  Total words
```{r}
r2 <- lm(unlist(log(author_count_measures[,"author_n"])) ~ unlist(log(author_count_measures[,"word_total"]))) %>%
    summary() %>%
   pluck("r.squared") %>%
  round(2)
```

Quantity of language as a function of community size follows a power law, with an exponent of `r get_power_law_exponent(author_count_measures, "author_n","word_total")[[1]]`, meaning it's a Zipfs law (~1). And an $R^2$ = `r r2`!

```{r}
ggplot(author_count_measures, aes(x = author_n, y = word_total)) +
  geom_point() +
  geom_smooth(method = "lm")+
  scale_y_log10(name = "N total words (log)") +
  scale_x_log10(name = "N authors (log)")+
  theme_classic()
```

### N Posts 
Exp: `r get_power_law_exponent(author_count_measures, "author_n","posts_n_all")[[1]]`.

Low exp -> more inequality (large communities with lots of posts)

```{r}
ggplot(author_count_measures, aes(x = author_n, y = posts_n_all)) +
  geom_point() +
  geom_smooth(method = "lm")+
  scale_y_log10(name = "N posts (log)") +
  scale_x_log10(name = "N authors (log)")+
  theme_classic()
```

### Comments to post ratio
Exp: `r get_power_law_exponent(author_count_measures, "author_n","comments_posts_ratio")[[1]]`.

```{r}
ggplot(author_count_measures, aes(x = author_n, y = comments_posts_ratio)) +
  geom_point() +
  geom_smooth(method = "lm")+
  scale_y_log10(name = "comments/posts (log)") +
  scale_x_log10(name = "N authors (log)")+
  theme_classic()

cor.test(log(author_count_measures$author_n), log(author_count_measures$comments_posts_ratio)) %>%
  tidy() %>%
  kable()
```

# Word Types
```{r}
WORD_TYPES <-  here("exploratory_analyses/04_systematic_sample_tidy/data/word_type_counts.csv")
word_types <- read_csv(WORD_TYPES) %>%
  mutate(subreddit = str_replace(subreddit, "_word_counts2.csv", ""))

```


## Pairwise correlations
```{r, fig.width = 8, fig.height = 8}

author_count_measures %>%
  select(subreddit, word_total, author_n, comments_n_all, posts_n_all, comments_posts_ratio) %>%
  #select(-author_rank) %>%
  left_join(word_types) %>%
  mutate_at(vars(word_total, author_n, comments_n_all, posts_n_all, comments_posts_ratio, n_word_types), log) %>%
  select(-subreddit) %>%
  make_corr_plot()

```
